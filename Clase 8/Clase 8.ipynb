{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 8: Métodos de ensamblaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model as lm\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Bagging\n",
    "\n",
    "Vamos a ajustar un modelo sencillo con bagging aplicado a una regresión logística a modo de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan = pd.read_csv('loan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partición train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(loan.index, test_size = 0.3)\n",
    "train = loan.loc[split[0]]\n",
    "test = loan.loc[split[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustar una regresión logística simple a modo de ejemplo. esta vez lo haremos con la librería sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr, Xtr = patsy.dmatrices(\"\"\"SeriousDlqin2yrs ~ RevolvingUtilizationOfUnsecuredLines + DebtRatio +\n",
    "                   np.log(MonthlyIncome + 1)\"\"\",\n",
    "                  data = train)\n",
    "yte, Xte = patsy.dmatrices(\"\"\"SeriousDlqin2yrs ~ RevolvingUtilizationOfUnsecuredLines + DebtRatio +\n",
    "                   np.log(MonthlyIncome + 1)\"\"\",\n",
    "                   data = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = lm.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = ft.fit(Xtr, np.ravel(ytr))\n",
    "preds = ft.predict(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evaluemos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(yte, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre recordar que el desbalance puede afectar en gran medida el resultado del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una opción es el undersampling, es decir reducir la muestra hasta tener equilibrio entre las dos clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train[train.SeriousDlqin2yrs == 1]\n",
    "n1 = train_1.shape[0]\n",
    "train_0 = train[train.SeriousDlqin2yrs == 0].sample(n1)\n",
    "train_bal = pd.concat([train_1, train_0])\n",
    "\n",
    "ytr, Xtr = patsy.dmatrices(\"\"\"SeriousDlqin2yrs ~ RevolvingUtilizationOfUnsecuredLines + DebtRatio +\n",
    "                   np.log(MonthlyIncome + 1)\"\"\",\n",
    "                  data = train_bal)\n",
    "ft = lm.LogisticRegression()\n",
    "ft = ft.fit(Xtr, np.ravel(ytr))\n",
    "preds = ft.predict(Xte)\n",
    "metrics.confusion_matrix(yte, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos una función que haga un ajuste a partir de un muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(df, Xte, ft):\n",
    "    ytr, Xtr = patsy.dmatrices(\"\"\"SeriousDlqin2yrs ~ RevolvingUtilizationOfUnsecuredLines + DebtRatio +\n",
    "                   np.log(MonthlyIncome + 1)\"\"\",\n",
    "                  data = df)\n",
    "    preds = ft.fit(Xtr, np.ravel(ytr)).predict(Xte)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.zeros((100, Xte.shape[0]))\n",
    "n = train_bal.shape[0]\n",
    "ft = lm.LogisticRegression()\n",
    "      \n",
    "for i in range(100):\n",
    "    df = train_bal.sample(n, replace = True)\n",
    "    M[i,:] = logistic(df, Xte, ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregan los resultados de acuerdo a la clase mayoitaria en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (M.sum(axis = 0) > 50) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(yte, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos aumentaron levemente los falsos negativos, pero disminuyeron notoriamente los falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, vamos a separar conjunto de train y test, la clase pasada lo hicimos manual, pero existen funciones para hacer esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función tiene algunos de los siguientes parámetros básicos.\n",
    "\n",
    "```RandomForestClassifier(n_estimators=10, criterion=’gini’,max_features = 'auto', max_depth=None, min_samples_split=2, min_samples_leaf=1,  max_leaf_nodes=None, n_jobs=1, class_weight=None)```\n",
    "\n",
    "- **n_estimators:** indica la cantidad de árboles a generar.\n",
    "- **criterion:** indica el criterio para el ajuste de árboles.\n",
    "- **max_depth:** profundida máxima de cada árbol\n",
    "- **max_features:** Corresponde al $m$, cuantas variables se van a tomar al azar para la partición.\n",
    "- **min_samples_split:** minima cantidad de muestrar para una división.\n",
    "- **max_leaf_nodes:** máxima cantidad de nodos en el árbol final.\n",
    "- **n_jobs:** Cantidad de CPU a usar en el ajuste\n",
    "- **class_weight:** peso a las ctegorias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 200)\n",
    "rffit = rf.fit(Xtr, np.ravel(ytr))\n",
    "preds_rf = rffit.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(yte, preds_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible predecir las probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_prob = rffit.predict_proba(Xte)\n",
    "roc = metrics.roc_curve(yte, preds_prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(roc[0], roc[1])\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.auc(roc[0], roc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importancia Relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rffit.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aquí se desprende que **RevolvingUtilizationOfUnsecuredLines** es la variable que más afecta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los argumentos básicos son los siguientes\n",
    "\n",
    "```GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, max_features=None, max_leaf_nodes=None, validation_fraction=0.1)```\n",
    "\n",
    "- **loss** función de pérdida, solo tiene la devianza y una pérdida exponencial\n",
    "- **learning_rate** Tasa de aprendizaje, es un parámetro de encogimiento de los nuevos modelos incorporados.\n",
    "- **n_estimators** indica la cantidad de iteraciones del algoritmo, es decir cuantos nuevos modelos.\n",
    "- **subsample** Cantidad de puntos al azar para ajustar el algoritmo, se usar para el SGBM\n",
    "Notar que el resto de los argumentos hacen referencia a los árboles que va a ajustar el GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators = 100)\n",
    "gbmfit = gbm.fit(Xtr, np.ravel(ytr))\n",
    "preds_gbm = gbmfit.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(yte, preds_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_prob_gbm = gbmfit.predict_proba(Xte)\n",
    "roc = metrics.roc_curve(yte, preds_prob_gbm[:, 1])\n",
    "\n",
    "plt.plot(roc[0], roc[1])\n",
    "plt.plot([0,1], [0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.auc(roc[0], roc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
